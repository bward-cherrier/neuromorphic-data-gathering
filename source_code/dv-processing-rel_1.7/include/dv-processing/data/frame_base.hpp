// automatically generated by the FlatBuffers compiler, do not modify

#ifndef FLATBUFFERS_GENERATED_FRAME_DV_H_
#define FLATBUFFERS_GENERATED_FRAME_DV_H_

#include "../external/flatbuffers/flatbuffers.h"

#include "../core/time.hpp"
#include "cvector.hpp"

#include <opencv2/core/mat.hpp>

#include <ostream>

namespace dv {

struct FrameFlatbuffer;
struct Frame;

bool operator==(const Frame &lhs, const Frame &rhs);

inline const flatbuffers::TypeTable *FrameTypeTable();

/// Format values are compatible with OpenCV.
/// Pixel layout follows OpenCV standard.
enum class FrameFormat : int8_t {
	GRAY [[deprecated("Please use the OPENCV_8U_C1 enum value instead.")]] = 0, // Old API compat.
	OPENCV_8U_C1                                                           = 0,
	OPENCV_8S_C1                                                           = 1,
	OPENCV_16U_C1                                                          = 2,
	OPENCV_16S_C1                                                          = 3,
	OPENCV_32S_C1                                                          = 4,
	OPENCV_32F_C1                                                          = 5,
	OPENCV_64F_C1                                                          = 6,
	OPENCV_16F_C1                                                          = 7,
	OPENCV_8U_C2                                                           = 8,
	OPENCV_8S_C2                                                           = 9,
	OPENCV_16U_C2                                                          = 10,
	OPENCV_16S_C2                                                          = 11,
	OPENCV_32S_C2                                                          = 12,
	OPENCV_32F_C2                                                          = 13,
	OPENCV_64F_C2                                                          = 14,
	OPENCV_16F_C2                                                          = 15,
	BGR [[deprecated("Please use the OPENCV_8U_C3 enum value instead.")]]  = 16, // Old API compat.
	OPENCV_8U_C3                                                           = 16,
	OPENCV_8S_C3                                                           = 17,
	OPENCV_16U_C3                                                          = 18,
	OPENCV_16S_C3                                                          = 19,
	OPENCV_32S_C3                                                          = 20,
	OPENCV_32F_C3                                                          = 21,
	OPENCV_64F_C3                                                          = 22,
	OPENCV_16F_C3                                                          = 23,
	BGRA [[deprecated("Please use the OPENCV_8U_C4 enum value instead.")]] = 24, // Old API compat.
	OPENCV_8U_C4                                                           = 24,
	OPENCV_8S_C4                                                           = 25,
	OPENCV_16U_C4                                                          = 26,
	OPENCV_16S_C4                                                          = 27,
	OPENCV_32S_C4                                                          = 28,
	OPENCV_32F_C4                                                          = 29,
	OPENCV_64F_C4                                                          = 30,
	OPENCV_16F_C4                                                          = 31,
	MIN                                                                    = OPENCV_8U_C1,
	MAX                                                                    = OPENCV_16F_C4
};

inline const FrameFormat (&EnumValuesFrameFormat())[32] {
	static const FrameFormat values[] = {FrameFormat::OPENCV_8U_C1, FrameFormat::OPENCV_8S_C1,
		FrameFormat::OPENCV_16U_C1, FrameFormat::OPENCV_16S_C1, FrameFormat::OPENCV_32S_C1, FrameFormat::OPENCV_32F_C1,
		FrameFormat::OPENCV_64F_C1, FrameFormat::OPENCV_16F_C1, FrameFormat::OPENCV_8U_C2, FrameFormat::OPENCV_8S_C2,
		FrameFormat::OPENCV_16U_C2, FrameFormat::OPENCV_16S_C2, FrameFormat::OPENCV_32S_C2, FrameFormat::OPENCV_32F_C2,
		FrameFormat::OPENCV_64F_C2, FrameFormat::OPENCV_16F_C2, FrameFormat::OPENCV_8U_C3, FrameFormat::OPENCV_8S_C3,
		FrameFormat::OPENCV_16U_C3, FrameFormat::OPENCV_16S_C3, FrameFormat::OPENCV_32S_C3, FrameFormat::OPENCV_32F_C3,
		FrameFormat::OPENCV_64F_C3, FrameFormat::OPENCV_16F_C3, FrameFormat::OPENCV_8U_C4, FrameFormat::OPENCV_8S_C4,
		FrameFormat::OPENCV_16U_C4, FrameFormat::OPENCV_16S_C4, FrameFormat::OPENCV_32S_C4, FrameFormat::OPENCV_32F_C4,
		FrameFormat::OPENCV_64F_C4, FrameFormat::OPENCV_16F_C4};
	return values;
}

inline const char *const *EnumNamesFrameFormat() {
	static const char *const names[] = {"OPENCV_8U_C1", "OPENCV_8S_C1", "OPENCV_16U_C1", "OPENCV_16S_C1",
		"OPENCV_32S_C1", "OPENCV_32F_C1", "OPENCV_64F_C1", "OPENCV_16F_C1", "OPENCV_8U_C2", "OPENCV_8S_C2",
		"OPENCV_16U_C2", "OPENCV_16S_C2", "OPENCV_32S_C2", "OPENCV_32F_C2", "OPENCV_64F_C2", "OPENCV_16F_C2",
		"OPENCV_8U_C3", "OPENCV_8S_C3", "OPENCV_16U_C3", "OPENCV_16S_C3", "OPENCV_32S_C3", "OPENCV_32F_C3",
		"OPENCV_64F_C3", "OPENCV_16F_C3", "OPENCV_8U_C4", "OPENCV_8S_C4", "OPENCV_16U_C4", "OPENCV_16S_C4",
		"OPENCV_32S_C4", "OPENCV_32F_C4", "OPENCV_64F_C4", "OPENCV_16F_C4", nullptr};
	return names;
}

inline const char *EnumNameFrameFormat(FrameFormat e) {
	if (e < FrameFormat::OPENCV_8U_C1 || e > FrameFormat::OPENCV_16F_C4)
		return "";
	const size_t index = static_cast<int>(e);
	return EnumNamesFrameFormat()[index];
}

/// Image data source
enum class FrameSource : int8_t {
	/// Undefined source, this value indicates that source field shouldn't be considered at all
	UNDEFINED = 0 /// Image comes from a frame sensor
		,
	SENSOR = 1 /// Image was accumulated
		,
	ACCUMULATION = 2 /// Image was accumulated using motion compensation
		,
	MOTION_COMPENSATION = 3 /// Image is synthetic, it does not represent any real data
		,
	SYNTHETIC = 4 /// Reconstructed image, it may come from a neural network that convert events to images
		,
	RECONSTRUCTION = 5 /// The image is designated for visualization only
		,
	VISUALIZATION = 6 /// Other sources, can be used to indicate a custom algorithm for image generation
		,
	OTHER = 7,
	MIN   = UNDEFINED,
	MAX   = OTHER
};

inline const FrameSource (&EnumValuesFrameSource())[8] {
	static const FrameSource values[]
		= {FrameSource::UNDEFINED, FrameSource::SENSOR, FrameSource::ACCUMULATION, FrameSource::MOTION_COMPENSATION,
			FrameSource::SYNTHETIC, FrameSource::RECONSTRUCTION, FrameSource::VISUALIZATION, FrameSource::OTHER};
	return values;
}

inline const char *const *EnumNamesFrameSource() {
	static const char *const names[] = {"UNDEFINED", "SENSOR", "ACCUMULATION", "MOTION_COMPENSATION", "SYNTHETIC",
		"RECONSTRUCTION", "VISUALIZATION", "OTHER", nullptr};
	return names;
}

inline const char *EnumNameFrameSource(FrameSource e) {
	if (e < FrameSource::UNDEFINED || e > FrameSource::OTHER)
		return "";
	const size_t index = static_cast<int>(e);
	return EnumNamesFrameSource()[index];
}

struct Frame : public flatbuffers::NativeTable {
	typedef FrameFlatbuffer TableType;

	static FLATBUFFERS_CONSTEXPR const char *GetFullyQualifiedName() {
		return "dv.Frame";
	}

	// Timestamp represents start of exposure, or closest possible moment to it.
	int64_t timestamp;
	int16_t positionX;
	int16_t positionY;
	cv::Mat image;
	dv::Duration exposure;
	FrameSource source;

	Frame() : timestamp(0), positionX(0), positionY(0), exposure(0), source(FrameSource::UNDEFINED) {
	}

	// Legacy-support Constructor
	Frame(int64_t _timestamp, int64_t _timestampStartOfFrame, int64_t _timestampEndOfFrame,
		int64_t _timestampStartOfExposure, int64_t _timestampEndOfExposure, FrameFormat _format, int16_t _sizeX,
		int16_t _sizeY, int16_t _positionX, int16_t _positionY, const dv::cvector<uint8_t> &_pixels) :
		timestamp{_timestamp},
		positionX{_positionX},
		positionY{_positionY},
		image(cv::Mat(_sizeY, _sizeX, static_cast<int>(_format))),
		exposure{_timestampEndOfExposure - _timestampStartOfExposure},
		source{FrameSource::UNDEFINED} {
		cv::Mat tempMap(_sizeY, _sizeX, static_cast<int>(_format), const_cast<uint8_t *>(_pixels.data()));
		tempMap.copyTo(image);
	}

	// Modern Constructor
	Frame(int64_t _timestamp, int64_t _exposure, int16_t _positionX, int16_t _positionY, const cv::Mat &_image,
		dv::FrameSource _source) :
		timestamp{_timestamp},
		positionX{_positionX},
		positionY{_positionY},
		image{_image},
		exposure{_exposure},
		source{_source} {
	}

	// Minimal Constructor
	Frame(int64_t _timestamp, const cv::Mat &_image) :
		timestamp{_timestamp},
		positionX{0},
		positionY{0},
		image{_image},
		exposure{0},
		source{FrameSource::UNDEFINED} {
	}

	friend std::ostream &operator<<(std::ostream &os, const Frame &frame) {
		os << fmt::format("Frame with dimensions [{}x{}] at time {}; source: {}", frame.image.cols, frame.image.rows,
			frame.timestamp, *EnumNameFrameSource(frame.source));
		return os;
	}
};

inline bool operator==(const Frame &lhs, const Frame &rhs) {
	return (lhs.timestamp == rhs.timestamp) && (lhs.positionX == rhs.positionX) && (lhs.positionY == rhs.positionY)
		&& ((lhs.image.total() == rhs.image.total()) && (lhs.image.elemSize() == rhs.image.elemSize())
			&& ((lhs.image.data == rhs.image.data)
				|| (lhs.image.isContinuous() && rhs.image.isContinuous()
					&& (memcmp(lhs.image.data, rhs.image.data, (lhs.image.total() * lhs.image.elemSize())) == 0))))
		&& (lhs.exposure == rhs.exposure) && (lhs.source == rhs.source);
}

struct FrameFlatbuffer FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
	typedef Frame NativeTableType;
	static FLATBUFFERS_CONSTEXPR const char *identifier = "FRME";

	static const flatbuffers::TypeTable *MiniReflectTypeTable() {
		return FrameTypeTable();
	}

	static FLATBUFFERS_CONSTEXPR const char *GetFullyQualifiedName() {
		return "dv.Frame";
	}

	enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
		VT_TIMESTAMP                = 4,
		VT_TIMESTAMPSTARTOFFRAME    = 6,
		VT_TIMESTAMPENDOFFRAME      = 8,
		VT_TIMESTAMPSTARTOFEXPOSURE = 10,
		VT_TIMESTAMPENDOFEXPOSURE   = 12,
		VT_FORMAT                   = 14,
		VT_SIZEX                    = 16,
		VT_SIZEY                    = 18,
		VT_POSITIONX                = 20,
		VT_POSITIONY                = 22,
		VT_PIXELS                   = 24,
		VT_EXPOSURE                 = 26,
		VT_SOURCE                   = 28
	};

	/// Central timestamp (Âµs), corresponds to exposure midpoint.
	int64_t timestamp() const {
		return GetField<int64_t>(VT_TIMESTAMP, 0);
	}

	/// Start of Frame (SOF) timestamp.
	int64_t timestampStartOfFrame() const {
		return GetField<int64_t>(VT_TIMESTAMPSTARTOFFRAME, 0);
	}

	/// End of Frame (EOF) timestamp.
	int64_t timestampEndOfFrame() const {
		return GetField<int64_t>(VT_TIMESTAMPENDOFFRAME, 0);
	}

	/// Start of Exposure (SOE) timestamp.
	int64_t timestampStartOfExposure() const {
		return GetField<int64_t>(VT_TIMESTAMPSTARTOFEXPOSURE, 0);
	}

	/// End of Exposure (EOE) timestamp.
	int64_t timestampEndOfExposure() const {
		return GetField<int64_t>(VT_TIMESTAMPENDOFEXPOSURE, 0);
	}

	/// Pixel format (grayscale, RGB, ...).
	FrameFormat format() const {
		return static_cast<FrameFormat>(GetField<int8_t>(VT_FORMAT, 0));
	}

	/// X axis length in pixels.
	int16_t sizeX() const {
		return GetField<int16_t>(VT_SIZEX, 0);
	}

	/// Y axis length in pixels.
	int16_t sizeY() const {
		return GetField<int16_t>(VT_SIZEY, 0);
	}

	/// X axis position (upper left offset) in pixels.
	int16_t positionX() const {
		return GetField<int16_t>(VT_POSITIONX, 0);
	}

	/// Y axis position (upper left offset) in pixels.
	int16_t positionY() const {
		return GetField<int16_t>(VT_POSITIONY, 0);
	}

	/// Pixel values, 8bit depth.
	const flatbuffers::Vector<uint8_t> *pixels() const {
		return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_PIXELS);
	}

	/// Exposure duration
	int64_t exposure() const {
		return GetField<int64_t>(VT_EXPOSURE, 0);
	}

	/// Source of the image data, whether it's from sensor or from some form of event accumulation
	FrameSource source() const {
		return static_cast<FrameSource>(GetField<int8_t>(VT_SOURCE, 0));
	}

	bool Verify(flatbuffers::Verifier &verifier) const {
		return VerifyTableStart(verifier) && VerifyField<int64_t>(verifier, VT_TIMESTAMP)
			&& VerifyField<int64_t>(verifier, VT_TIMESTAMPSTARTOFFRAME)
			&& VerifyField<int64_t>(verifier, VT_TIMESTAMPENDOFFRAME)
			&& VerifyField<int64_t>(verifier, VT_TIMESTAMPSTARTOFEXPOSURE)
			&& VerifyField<int64_t>(verifier, VT_TIMESTAMPENDOFEXPOSURE) && VerifyField<int8_t>(verifier, VT_FORMAT)
			&& VerifyField<int16_t>(verifier, VT_SIZEX) && VerifyField<int16_t>(verifier, VT_SIZEY)
			&& VerifyField<int16_t>(verifier, VT_POSITIONX) && VerifyField<int16_t>(verifier, VT_POSITIONY)
			&& VerifyOffset(verifier, VT_PIXELS) && verifier.VerifyVector(pixels())
			&& VerifyField<int64_t>(verifier, VT_EXPOSURE) && VerifyField<int8_t>(verifier, VT_SOURCE)
			&& verifier.EndTable();
	}

	Frame *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
	void UnPackTo(Frame *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
	static void UnPackToFrom(
		Frame *_o, const FrameFlatbuffer *_fb, const flatbuffers::resolver_function_t *_resolver = nullptr);
	static flatbuffers::Offset<FrameFlatbuffer> Pack(flatbuffers::FlatBufferBuilder &_fbb, const Frame *_o,
		const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct FrameBuilder {
	flatbuffers::FlatBufferBuilder &fbb_;
	flatbuffers::uoffset_t start_;

	void add_timestamp(int64_t timestamp) {
		fbb_.AddElement<int64_t>(FrameFlatbuffer::VT_TIMESTAMP, timestamp, 0);
	}

	void add_timestampStartOfFrame(int64_t timestampStartOfFrame) {
		fbb_.AddElement<int64_t>(FrameFlatbuffer::VT_TIMESTAMPSTARTOFFRAME, timestampStartOfFrame, 0);
	}

	void add_timestampEndOfFrame(int64_t timestampEndOfFrame) {
		fbb_.AddElement<int64_t>(FrameFlatbuffer::VT_TIMESTAMPENDOFFRAME, timestampEndOfFrame, 0);
	}

	void add_timestampStartOfExposure(int64_t timestampStartOfExposure) {
		fbb_.AddElement<int64_t>(FrameFlatbuffer::VT_TIMESTAMPSTARTOFEXPOSURE, timestampStartOfExposure, 0);
	}

	void add_timestampEndOfExposure(int64_t timestampEndOfExposure) {
		fbb_.AddElement<int64_t>(FrameFlatbuffer::VT_TIMESTAMPENDOFEXPOSURE, timestampEndOfExposure, 0);
	}

	void add_format(FrameFormat format) {
		fbb_.AddElement<int8_t>(FrameFlatbuffer::VT_FORMAT, static_cast<int8_t>(format), 0);
	}

	void add_sizeX(int16_t sizeX) {
		fbb_.AddElement<int16_t>(FrameFlatbuffer::VT_SIZEX, sizeX, 0);
	}

	void add_sizeY(int16_t sizeY) {
		fbb_.AddElement<int16_t>(FrameFlatbuffer::VT_SIZEY, sizeY, 0);
	}

	void add_positionX(int16_t positionX) {
		fbb_.AddElement<int16_t>(FrameFlatbuffer::VT_POSITIONX, positionX, 0);
	}

	void add_positionY(int16_t positionY) {
		fbb_.AddElement<int16_t>(FrameFlatbuffer::VT_POSITIONY, positionY, 0);
	}

	void add_pixels(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> pixels) {
		fbb_.AddOffset(FrameFlatbuffer::VT_PIXELS, pixels);
	}

	void add_exposure(int64_t exposure) {
		fbb_.AddElement<int64_t>(FrameFlatbuffer::VT_EXPOSURE, exposure, 0);
	}

	void add_source(FrameSource source) {
		fbb_.AddElement<int8_t>(FrameFlatbuffer::VT_SOURCE, static_cast<int8_t>(source), 0);
	}

	explicit FrameBuilder(flatbuffers::FlatBufferBuilder &_fbb) : fbb_(_fbb) {
		start_ = fbb_.StartTable();
	}

	FrameBuilder &operator=(const FrameBuilder &);

	flatbuffers::Offset<FrameFlatbuffer> Finish() {
		const auto end = fbb_.EndTable(start_);
		auto o         = flatbuffers::Offset<FrameFlatbuffer>(end);
		return o;
	}
};

inline flatbuffers::Offset<FrameFlatbuffer> CreateFrame(flatbuffers::FlatBufferBuilder &_fbb, int64_t timestamp = 0,
	int64_t timestampStartOfFrame = 0, int64_t timestampEndOfFrame = 0, int64_t timestampStartOfExposure = 0,
	int64_t timestampEndOfExposure = 0, FrameFormat format = FrameFormat::OPENCV_8U_C1, int16_t sizeX = 0,
	int16_t sizeY = 0, int16_t positionX = 0, int16_t positionY = 0,
	flatbuffers::Offset<flatbuffers::Vector<uint8_t>> pixels = 0, int64_t exposure = 0,
	FrameSource source = FrameSource::UNDEFINED) {
	FrameBuilder builder_(_fbb);
	builder_.add_exposure(exposure);
	builder_.add_timestampEndOfExposure(timestampEndOfExposure);
	builder_.add_timestampStartOfExposure(timestampStartOfExposure);
	builder_.add_timestampEndOfFrame(timestampEndOfFrame);
	builder_.add_timestampStartOfFrame(timestampStartOfFrame);
	builder_.add_timestamp(timestamp);
	builder_.add_pixels(pixels);
	builder_.add_positionY(positionY);
	builder_.add_positionX(positionX);
	builder_.add_sizeY(sizeY);
	builder_.add_sizeX(sizeX);
	builder_.add_source(source);
	builder_.add_format(format);
	return builder_.Finish();
}

inline flatbuffers::Offset<FrameFlatbuffer> CreateFrameDirect(flatbuffers::FlatBufferBuilder &_fbb,
	int64_t timestamp = 0, int64_t timestampStartOfFrame = 0, int64_t timestampEndOfFrame = 0,
	int64_t timestampStartOfExposure = 0, int64_t timestampEndOfExposure = 0,
	FrameFormat format = FrameFormat::OPENCV_8U_C1, int16_t sizeX = 0, int16_t sizeY = 0, int16_t positionX = 0,
	int16_t positionY = 0, const std::vector<uint8_t> *pixels = nullptr, int64_t exposure = 0,
	FrameSource source = FrameSource::UNDEFINED) {
	auto pixels__ = pixels ? _fbb.CreateVector<uint8_t>(*pixels) : 0;
	return dv::CreateFrame(_fbb, timestamp, timestampStartOfFrame, timestampEndOfFrame, timestampStartOfExposure,
		timestampEndOfExposure, format, sizeX, sizeY, positionX, positionY, pixels__, exposure, source);
}

flatbuffers::Offset<FrameFlatbuffer> CreateFrame(
	flatbuffers::FlatBufferBuilder &_fbb, const Frame *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

inline Frame *FrameFlatbuffer::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
	auto _o = new Frame();
	UnPackTo(_o, _resolver);
	return _o;
}

inline void FrameFlatbuffer::UnPackTo(Frame *_o, const flatbuffers::resolver_function_t *_resolver) const {
	(void) _o;
	(void) _resolver;
	UnPackToFrom(_o, this, _resolver);
}

inline void FrameFlatbuffer::UnPackToFrom(
	Frame *_o, const FrameFlatbuffer *_fb, const flatbuffers::resolver_function_t *_resolver) {
	(void) _o;
	(void) _fb;
	(void) _resolver;
	{
		auto startOfExposure = _fb->timestampStartOfExposure();
		auto _e              = startOfExposure > 0 ? startOfExposure : _fb->timestamp();
		_o->timestamp        = _e;
	};
	{
		auto _e       = _fb->positionX();
		_o->positionX = _e;
	};
	{
		auto _e       = _fb->positionY();
		_o->positionY = _e;
	};
	{
		auto _e = _fb->pixels();
		if (_e) {
			auto sizeX  = _fb->sizeX();
			auto sizeY  = _fb->sizeY();
			auto format = _fb->format();
			_o->image   = cv::Mat(sizeY, sizeX, static_cast<int>(format));
			cv::Mat tempMap(sizeY, sizeX, static_cast<int>(format), const_cast<uint8_t *>(_e->data()));
			tempMap.copyTo(_o->image);
		}
	};
	{
		auto _e      = _fb->exposure();
		_o->exposure = dv::Duration(_e);
		// Support for old timestamp
		if (_o->exposure == dv::Duration(0)) {
			auto startOfExposure = _fb->timestampStartOfExposure();
			auto endOfExposure   = _fb->timestampEndOfExposure();
			// In worst case these are zeros as well
			_o->exposure = dv::Duration(endOfExposure - startOfExposure);
		}
	};
	{
		auto _e    = _fb->source();
		_o->source = _e;
	};
}

inline flatbuffers::Offset<FrameFlatbuffer> FrameFlatbuffer::Pack(
	flatbuffers::FlatBufferBuilder &_fbb, const Frame *_o, const flatbuffers::rehasher_function_t *_rehasher) {
	return CreateFrame(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<FrameFlatbuffer> CreateFrame(
	flatbuffers::FlatBufferBuilder &_fbb, const Frame *_o, const flatbuffers::rehasher_function_t *_rehasher) {
	(void) _rehasher;
	(void) _o;

	struct _VectorArgs {
		flatbuffers::FlatBufferBuilder *__fbb;
		const Frame *__o;
		const flatbuffers::rehasher_function_t *__rehasher;
	} _va = {&_fbb, _o, _rehasher};

	(void) _va;
	auto _timestamp                = _o->timestamp;
	auto _timestampStartOfFrame    = 0;
	auto _timestampEndOfFrame      = 0;
	auto _timestampStartOfExposure = _o->timestamp;
	auto _timestampEndOfExposure   = _o->timestamp + _o->exposure.count();
	auto _format                   = static_cast<dv::FrameFormat>(_o->image.type());
	auto _sizeX                    = static_cast<int16_t>(_o->image.cols);
	auto _sizeY                    = static_cast<int16_t>(_o->image.rows);
	auto _positionX                = _o->positionX;
	auto _positionY                = _o->positionY;
	// Clone the image if it is non-continuous memory, it will cause an extra copy.
	// This should generally be fine, since non-continuous memory is quite a corner case.
	cv::Mat pixelData = _o->image.isContinuous() ? _o->image : _o->image.clone();
	size_t imageSize  = pixelData.elemSize() * pixelData.total();
	auto _pixels      = imageSize ? _fbb.CreateVector(pixelData.data, imageSize) : 0;
	auto _exposure    = _o->exposure.count();
	auto _source      = _o->source;
	return dv::CreateFrame(_fbb, _timestamp, _timestampStartOfFrame, _timestampEndOfFrame, _timestampStartOfExposure,
		_timestampEndOfExposure, _format, _sizeX, _sizeY, _positionX, _positionY, _pixels, _exposure, _source);
}

inline const flatbuffers::TypeTable *FrameFormatTypeTable() {
	static const flatbuffers::TypeCode type_codes[] = {
		{flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
		{flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
		{flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
		{flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
		{flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
		{flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
		{flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
		{flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
		{flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
		{flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
		{flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0}
    };
	static const flatbuffers::TypeFunction type_refs[] = {FrameFormatTypeTable};
	static const char *const names[]       = {"OPENCV_8U_C1", "OPENCV_8S_C1", "OPENCV_16U_C1", "OPENCV_16S_C1",
			  "OPENCV_32S_C1", "OPENCV_32F_C1", "OPENCV_64F_C1", "OPENCV_16F_C1", "OPENCV_8U_C2", "OPENCV_8S_C2",
			  "OPENCV_16U_C2", "OPENCV_16S_C2", "OPENCV_32S_C2", "OPENCV_32F_C2", "OPENCV_64F_C2", "OPENCV_16F_C2",
			  "OPENCV_8U_C3", "OPENCV_8S_C3", "OPENCV_16U_C3", "OPENCV_16S_C3", "OPENCV_32S_C3", "OPENCV_32F_C3",
			  "OPENCV_64F_C3", "OPENCV_16F_C3", "OPENCV_8U_C4", "OPENCV_8S_C4", "OPENCV_16U_C4", "OPENCV_16S_C4",
			  "OPENCV_32S_C4", "OPENCV_32F_C4", "OPENCV_64F_C4", "OPENCV_16F_C4"};
	static const flatbuffers::TypeTable tt = {flatbuffers::ST_ENUM, 32, type_codes, type_refs, nullptr, names};
	return &tt;
}

inline const flatbuffers::TypeTable *FrameSourceTypeTable() {
	static const flatbuffers::TypeCode type_codes[] = {
		{flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
		{flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0},
		{flatbuffers::ET_CHAR, 0, 0},
        {flatbuffers::ET_CHAR, 0, 0}
    };
	static const flatbuffers::TypeFunction type_refs[] = {FrameSourceTypeTable};
	static const char *const names[]       = {"UNDEFINED", "SENSOR", "ACCUMULATION", "MOTION_COMPENSATION", "SYNTHETIC",
			  "RECONSTRUCTION", "VISUALIZATION", "OTHER"};
	static const flatbuffers::TypeTable tt = {flatbuffers::ST_ENUM, 8, type_codes, type_refs, nullptr, names};
	return &tt;
}

inline const flatbuffers::TypeTable *FrameTypeTable() {
	static const flatbuffers::TypeCode type_codes[] = {
		{flatbuffers::ET_LONG,  0, -1},
        {flatbuffers::ET_LONG,  0, -1},
        {flatbuffers::ET_LONG,  0, -1},
		{flatbuffers::ET_LONG,  0, -1},
        {flatbuffers::ET_LONG,  0, -1},
        {flatbuffers::ET_CHAR,  0, 0 },
		{flatbuffers::ET_SHORT, 0, -1},
        {flatbuffers::ET_SHORT, 0, -1},
        {flatbuffers::ET_SHORT, 0, -1},
		{flatbuffers::ET_SHORT, 0, -1},
        {flatbuffers::ET_UCHAR, 1, -1},
        {flatbuffers::ET_LONG,  0, -1},
		{flatbuffers::ET_CHAR,  0, 1 }
    };
	static const flatbuffers::TypeFunction type_refs[] = {FrameFormatTypeTable, FrameSourceTypeTable};
	static const char *const names[]                   = {"timestamp", "timestampStartOfFrame", "timestampEndOfFrame",
						  "timestampStartOfExposure", "timestampEndOfExposure", "format", "sizeX", "sizeY", "positionX", "positionY",
						  "pixels", "exposure", "source"};
	static const flatbuffers::TypeTable tt = {flatbuffers::ST_TABLE, 13, type_codes, type_refs, nullptr, names};
	return &tt;
}

inline const dv::FrameFlatbuffer *GetFrame(const void *buf) {
	return flatbuffers::GetRoot<dv::FrameFlatbuffer>(buf);
}

inline const dv::FrameFlatbuffer *GetSizePrefixedFrame(const void *buf) {
	return flatbuffers::GetSizePrefixedRoot<dv::FrameFlatbuffer>(buf);
}

inline const char *FrameIdentifier() {
	return "FRME";
}

inline bool FrameBufferHasIdentifier(const void *buf) {
	return flatbuffers::BufferHasIdentifier(buf, FrameIdentifier());
}

inline bool VerifyFrameBuffer(flatbuffers::Verifier &verifier) {
	return verifier.VerifyBuffer<dv::FrameFlatbuffer>(FrameIdentifier());
}

inline bool VerifySizePrefixedFrameBuffer(flatbuffers::Verifier &verifier) {
	return verifier.VerifySizePrefixedBuffer<dv::FrameFlatbuffer>(FrameIdentifier());
}

inline void FinishFrameBuffer(flatbuffers::FlatBufferBuilder &fbb, flatbuffers::Offset<dv::FrameFlatbuffer> root) {
	fbb.Finish(root, FrameIdentifier());
}

inline void FinishSizePrefixedFrameBuffer(
	flatbuffers::FlatBufferBuilder &fbb, flatbuffers::Offset<dv::FrameFlatbuffer> root) {
	fbb.FinishSizePrefixed(root, FrameIdentifier());
}

inline std::unique_ptr<Frame> UnPackFrame(const void *buf, const flatbuffers::resolver_function_t *res = nullptr) {
	return std::unique_ptr<Frame>(GetFrame(buf)->UnPack(res));
}

} // namespace dv

// fmt compatibility for ostream class printing.
template<>
struct fmt::formatter<dv::Frame> : fmt::ostream_formatter {};

#endif // FLATBUFFERS_GENERATED_FRAME_DV_H_
